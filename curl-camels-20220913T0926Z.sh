#!/bin/bash


CURL_VERSION=$(curl --version | grep -oie "curl [0-9][0-9.]*" | head -n 1 | awk '{print $2}')
if [ -z "$CURL_VERSION" ]
then
CURL_VERSION=PARSE_ERROR
fi

CURL_USER_AGENT="curl/$CURL_VERSION/esg/3.0.68-20220909-170742/created/2022-09-13T09:26:48-06:00"


##############################################################################
#
# Climate Data Gateway download script
#
#
# Generated by: GDEX
#
# Template version: 0.4.7-curl-checksum
#
# Script generated user OpenId: guest
#
# Your download selection includes data that might be secured using API Token based
# authentication. Therefore, this script can have your api-token. If you
# re-generate your API Token after you download this script, the download will
# fail. If that happens, you can either re-download this script or you can replace
# the old API Token with the new one by going to the Account Home:
#
# https://www.earthsystemgrid.org/account/user/index.html
#
# and clicking on "API Token" link under "Personal Account". You will be asked
# to log into the application before you can view your API Token.
#
# Dataset
# camels
# fbc54ccc-5184-4f54-b306-f58112a34700
# https://gdex.ucar.edu/dataset/camels.html
# https://gdex.ucar.edu/dataset/id/fbc54ccc-5184-4f54-b306-f58112a34700.html
#
# Dataset Version
# 1.2
# 0925542f-ede4-4f25-9424-3fce02d43240
# https://gdex.ucar.edu/dataset/camels/version/1.2.html
# https://gdex.ucar.edu/dataset/version/id/0925542f-ede4-4f25-9424-3fce02d43240.html
#
##############################################################################

CACHE_FILE=.md5_results
MAX_RETRY=3


usage() {
    echo "Usage: $(basename $0) [flags]"
    echo "Flags is one of:"
    sed -n '/^while getopts/,/^done/  s/^\([^)]*\)[^#]*#\(.*$\)/\1 \2/p' $0
}
#defaults
debug=0
clean_work=1
verbose=1

#parse flags

while getopts ':pdvqko:' OPT; do

    case $OPT in

        p) clean_work=0;;       #	: preserve data that failed checksum
        o) output="$OPTARG";;   #<file>	: Write output for DML in the given file
        d) debug=1;;            #	: display debug information
        v) verbose=1;;          #       : be more verbose
        q) quiet=1;;            #	: be less verbose
        k) cert=1;;             #	: add --insecure (do not check certificate)
        \?) echo "Unknown option '$OPTARG'" >&2 && usage && exit 1;;
        \:) echo "Missing parameter for flag '$OPTARG'" >&2 && usage && exit 1;;
    esac
done
shift $(($OPTIND - 1))

if [[ "$output" ]]; then
    #check and prepare the file
    if [[ -f "$output" ]]; then
        read -p "Overwrite existing file $output? (y/N) " answ
        case $answ in y|Y|yes|Yes);; *) echo "Aborting then..."; exit 0;; esac
    fi
    : > "$output" || { echo "Can't write file $output"; break; }
fi

    ((debug)) && echo "debug=$debug, cert=$cert, verbose=$verbose, quiet=$quiet, clean_work=$clean_work"

##############################################################################


check_chksum() {
    local file="$1"
    local chk_type=$2
    local chk_value=$3
    local local_chksum

    case $chk_type in
        md5) local_chksum=$(md5 "$file" | awk {'print $NF'});;
        *) echo "Can't verify checksum." && return 0;;
    esac

    #verify
    ((debug)) && echo "local:$local_chksum vs remote:$chk_value"
    diff -q <(echo $local_chksum) <(echo $chk_value) >/dev/null
}

download() {

    curl="curl -L -C - --user-agent $CURL_USER_AGENT"

    if [[ "$cert" ]]; then
        curl="curl --insecure -L -C - --user-agent $CURL_USER_AGENT"
    else
        curl="curl -L -C - --user-agent $CURL_USER_AGENT"
    fi

    ((quiet)) && curl="$curl -s" || { ((!verbose)) && curl="$curl -S"; }

    ((debug)) && echo "curl command: $curl"

    while read line
    do
        # read csv here document into proper variables
        eval $(awk -F "' '" '{$0=substr($0,2,length($0)-2); $3=tolower($3); print "file=\""$1"\";url=\""$2"\";chksum_type=\""$3"\";chksum=\""$4"\""}' <(echo $line) )

        #Process the file
        echo -n "$file ..."

        #are we just writing a file?
        if [ "$output" ]; then
            echo "$file - $url" >> $output
            echo ""
            continue
        fi

        retry_counter=0

        while : ; do
                #if we have the file, check if it's already processed.
                [ -f "$file" ] && cached="$(grep $file $CACHE_FILE)" || unset cached

                #check it wasn't modified
                if [[ -n "$cached" && "$(stat -f "%m" $file)" == $(echo "$cached" | cut -d ' ' -f2) ]]; then
                    echo "Already downloaded and verified"
                    break
                fi

                # (if we had the file size, we could check before trying to complete)
                echo "Downloading"
                $curl -o "$file" $url || { failed=1; break; }

                #check if file is there
                if [[ -f "$file" ]]; then
                        ((debug)) && echo file found
                        if ! check_chksum "$file" $chksum_type $chksum; then
                                echo "  $chksum_type failed!"
                                if ((clean_work)); then
                                        rm "$file"

                                        #try again up to n times
                                        echo -n "  Re-downloading..."

                                        if [ $retry_counter -eq $MAX_RETRY ]
                                        then
                                            echo "  Re-tried file $file $MAX_RETRY times...."
                                            break
                                        fi
                                        retry_counter=`expr $retry_counter + 1`

                                        continue
                                else
                                        echo "  don't use -p or remove manually."
                                fi
                        else
                                echo "  $chksum_type ok. done!"
                                echo "$file" $(stat -f "%m" $file) $chksum >> $CACHE_FILE
                        fi
                fi
                #done!
                break
        done

        if ((failed)); then
            echo "download failed"

            unset failed
        fi

    done <<EOF--dataset.file.url.chksum_type.chksum
'basin_timeseries_v1p2_modelOutput_maurer.zip' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_maurer.zip' 'md5' '55fb2882136bc2f1e2ce35227396cc1f'
'basin_timeseries_v1p2_modelOutput_nldas.zip' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_nldas.zip' 'md5' '32c9973fb13d17a5268ed4affd95fb9a'
'basin_timeseries_v1p2_metForcing_obsFlow.zip' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_metForcing_obsFlow.zip' 'md5' '8e9a466710e8270b58f01d332a87184f'
'camels_vege.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_vege.txt' 'md5' 'f40e843defc1e654a800be9fe5fd5090'
'camels_name.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_name.txt' 'md5' 'c96491b32c4df55a31bead7ceca7d64b'
'camels_attributes_v2.0.pdf' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_attributes_v2.0.pdf' 'md5' '77a6c084c798a31fbd05594ee58a90c7'
'basin_timeseries_v1p2_modelOutput_daymet.zip' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_daymet.zip' 'md5' 'f2af624b6277b75b3e410d6a0365591a'
'camels_soil.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_soil.txt' 'md5' '8edb46a363a20b466a4b7105ba633767'
'camels_attributes_v2.0.xlsx' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_attributes_v2.0.xlsx' 'md5' '714c68bd5bb3314ca39b14f9467bd609'
'camels_clim.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_clim.txt' 'md5' '67f22592f3fb72c57df81358ce68458b'
'readme.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/readme.txt' 'md5' 'b37d64950e9d4c5c10a8b4ef82bc6219'
'camels_topo.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_topo.txt' 'md5' '0f6267838c40b1507b64582433bc0b8e'
'camels_hydro.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_hydro.txt' 'md5' '55ebdeb36c42ee7acdb998229c3edb3a'
'camels_geol.txt' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_geol.txt' 'md5' 'f5ce5de53eb1ea2532cda7e3b4813993'
'basin_set_full_res.zip' 'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_set_full_res.zip' 'md5' '958fe520f6c4062dbddbbb67cfc28985'
EOF--dataset.file.url.chksum_type.chksum

}


#
# MAIN
#
echo "Running $(basename $0) version: $version"

#do we have old results? Create the file if not
[ ! -f $CACHE_FILE ] && echo "#filename mtime checksum" > $CACHE_FILE

download

#remove duplicates (if any)
{ rm $CACHE_FILE && tail | awk '!x[$1]++' | tail > $CACHE_FILE; } < $CACHE_FILE
